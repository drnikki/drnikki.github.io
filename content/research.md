---
title: "Research"
date: 2024-02-10
published: true
---


My research agenda examines how software engineering practices are situated within contemporary political and social systems of power.  At parties, I tell people that I study software, people, and infrastructure and how those three combine in messy, violent, generative, and always complicated ways.  My main focus right now is writing a book (!!): while we might frequently hear accusations of tech being racist or transphobic (or just generally contributing to injustice), we don't often see the technical causes of those outcomes; my research uncovers those causes -- when we know _how_ we are making [bad thing], then we may have an opportunity to do things differently.  As an output of that research, I work on new technical practices. In this work, I ask questions like: (these questions are what I'm writing my book about)
- How can software engineers support social justice causes in their technical practices?
- How have the ways we make software been shaped by oppressive social forces?
- What new technical practices can we (engineers) integrate into our pipelines?
- How do the ways that we collect data about people shape the experiences of those people?

This is pretty abstract, but if you invite me for a talk (hint hint), I would give talks titled:
- "Abolitionist Data Practices: Applying political goals to data structures"
- "Is my database racist? How white supremacy structures our databases"
- "The history of data modeling" (this one is more exciting than it sounds, I swear!)
- "Beyond 'anti-racist' engineering: why anti-racism does not make better software"


## A note about methods
In order to unearth tehnical roots of injustice, I use several approaches, which I broadly consider to be three kinds of engineering:

Frequently, I perform what I call _historical engineering:_ I use close reading, archival analysis, and software design to excavate software engineering practices with the aim of historicizing and denaturalizing them. Using this method, I have reviewed texts from early data modelers, like E.F. Codd and Peter P.Y. Chen. I also recreate technology and practices identified in early patent documents to identify the moments in which problematic epistemologies were codified.*

I very often use _reverse engineering_ to hack into existing software applications and examine the choices made by their creators. Most often, I reverse engineer the Android applications of smart home devices to uncover the relational data models within. I analyze in-code annotations, create entity-relationship diagrams, and then examine those resultant models, again linking them back to systems of race and gender power. 
In my work, I have developed a method for performing a reverse engineering investigations within a specific sociotechnical context -- a situated analysis of the contextual epistemological frames embedded within relational paradigms. 

I also use _speculative engineering_ and software engineering to explore the potentiality and creative possibilities of existing and not-yet-created computational tools. In my speculative engineering process, I frequently suggest that the temporality of modern digital computing is incommensurate with the temporality of modern transgender lives. Following this, I design and build a trans-inclusive data model that demonstrates ways to actively subvert systems of racialized and gendered power. 

The most well-developed example of these methods in practice is in my dissertation,  [_Modeling Power: Data Models and the Production of Social Inequality_]({{< static url="Stevens-Dissertation.pdf" >}}). 

You can also read my other work (PDFs linked below):


Stevens, Nikki L., Anna Lauren Hoffman, Sarah Florini. [“The Unremarked Optimum: Whiteness, Optimization, and Control in The Database Revolution.”]({{< static url="unremarked-optimum.pdf" >}}) Review of Communication. June 2021.

Stevens, Nikki L. and Os Keyes. [“The Domestication of Facial Recognition Technology.”]({{< static url="seeing-infrastructure.pdf" >}}) Cultural Studies. March 2021

Stevens, Nikki L. [“Dataset Failures and Intersectional Data.”]({{< static url="dataset-failures.pdf" >}}) Journal of Cultural Analytics. March 2019.

Stevens, Nikki L. and Jacqueline Wernimont. [“Seeing 21st Century Data Bleed through the 15th Century Wound Man.”]({{< static url="Stevens_IEEE.pdf" >}}) IEEE Technology and Society. December 2018

## A note about community and context

My work with software and thinking about it's harms is greatly influenced by my time in open source software communities, and all of the collaborators with whom I have worked to make change. In the Drupal community, I founded the [Drupal Diversity and Inclusion Working Group](https://www.drupaldiversity.com).  With a few others, we grew the group from 5 to 700 over two years, and grappled with ways to make Drupal a safer space for folks from underrepresented groups.  

Out of this work came [Open Demographics](/open-source), a project that uses open source paradigmns to construct demographic questions, following the disability justice paradigm "Nothing About Us Without Us."  I've consulted for Mozilla, Stack Overflow, WordPress on asking demographic questions and then, doing the even tougher work of figuring out what comes next.  
